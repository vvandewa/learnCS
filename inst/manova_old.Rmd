---
title: 'Classification supervisée : séance 1'
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(exercise.checker = gradethis::grade_learnr)
```

---
title: 'Classification supervisée : fiche TP1, corrigé'
author: "Vincent Vandewalle, Cristian Preda"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_notebook:
    number_sections: yes
    toc: yes
  html_document:
    df_print: paged
    toc: yes
---

```{r}
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
```


# Reprise des exemples du cours

Lancer les commandes suivantes pour retrouver les résultats des exercices de la première séance de cours.


## Test du Chi-deux

```{r chi2}
V3V1<-matrix(c(30,20,30,20,10,15,10,15),4,2,byrow=TRUE)
V3V1
chi2 = chisq.test(V3V1)
str(chi2)
chi2
1-pchisq(5.3571,3) 
# ou en utilisant directement l'option
pchisq(5.3571, df = 3, lower.tail = FALSE)
sum(chi2$residuals^2)
```

1. Commenter code et résultats : ici on réalise un test du Chi-deux d'indépendance, on ne rejetterai pas l'hypothèse d'indépendance au risque $\alpha = 0,05$.

Vous pouvez aussi explorer plus en détail l'objet `chi2` :  question supplémentaire comment afficher les effectifs attendus sous l'hypothèse d'indépendance ? 

```{r expected, exercise = TRUE, exercise.setup = "chi2"}

```


<div id="expected-hint">
**Indice :** comment dit-on attendu en anglais ??? 
</div>

```{r expected-solution}
z
```

```{r expected-check}
grade_code()
```




## Test de Fisher
```{r Test de Fisher}
x <- c(4,5,7,8,9,2,3,4,6,7,8)
y <- c(rep(0,5),rep(1,6))
cbind(x,y)
lm(x~factor(y))
factor(y)
anova(lm(x~y))
SCF <- (mean(x[1:5])-mean(x))^2*5+(mean(x[6:11])-mean(x))^2*6
SCR <- sum(c((x[1:5]-mean(x[1:5]))^2,(x[6:11]-mean(x[6:11]))^2))
Fstat <- (SCF/1)/(SCR/9)
pval <- pf(Fstat,1,9,lower.tail=FALSE)
pval
Rsq <- SCF/(SCF+SCR)
Rsq
c(SCF,SCR,Fstat,pval,Rsq)
summary(lm(x~y))$r.squared
```
2. Commenter code et résultats : Ici on a réalisé un test de l'ANOVA, sous $H_0$ la statistique de test suit une loi de Fisher a $K-1$, $n-K$ degré de liberté, avec $K$ le nombre de classes et $n$ le nombre de données. Ici la probabilité critique est de $0,2686$ donc la variable $y$ n'a pas d'effet significatif sur la variable $x$ au risque $\alpha = 0,05$. 

**Attention** : en classification supervisée on veut prédire $y$ à partir de $x$ ! Mais le fait que la variance de $x$  soit bien expliquée par $y$ nous donne un bon indicateur du pouvoir prédictif $x$ sur $y$.

# Analyse préliminaire du jeu de données `iris`, ANOVA et MANOVA

## Analyse préliminaire du jeu de données `iris`

Dans cette partie on utilisera les données `iris`. 

3. Faire `data("iris")` dans R.

```{r chargement}
data("iris")
head(iris)
```

4. Renommer les variables "Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width","Species" en "X1", "X2", "X3", "X4", "Y".

```{r renommage}
names(iris) <- c("X1","X2","X3","X4","Y") 
```

5. Représenter graphiquement le lien entre X1 et Y :

```{r boxplot X1 sachant Y}
library(dplyr)
library(ggplot2)
iris %>% 
  ggplot(aes(x = Y, y = X1)) + 
  geom_boxplot()
```

Puis faire de même pour les autres variables : 
```{r boxplot des X en fonction de Y}
library("tidyr")
iris %>% 
  gather("variable","mesure",-Y) %>% 
  ggplot(aes(x = Y, y = mesure)) + 
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y")
```

Commenter : On voit que les variables pour lesquelles les classes sont les mieux séparées sont les variable $X_3$ et $X_4$.

## ANOVA

Réaliser l'ANOVA de X1 en fonction de Y et obtenir le $R^2$ associé, faire de même pour les autres variables. A partir des p-values, indiquer si la variable Y a une influence sur l'ensemble des variables. Quelle est la variable la mieux expliquée par Y ? 

Ajustement du modèle linéaire pour X1
```{r Ajustement du modèle linéaire pour X1 en fonction de Y}
lm(X1 ~ Y, data = iris)
shapiro.test(iris$X1[iris$Y == "setosa"])

# Test de normalité groupe par groupe : 
by(data = iris$X1, INDICES = iris$Y, shapiro.test)
# Ici accepte l'hypothèse de normalité dans chacune des classes

# Test d'homogénité des variances : 
bartlett.test(iris$X1, iris$Y)
# p-value = 0.0003345
# On rejette l'homogénéité des variances
# Attention : conclusion du test de l'ANOVA possiblement erronées

summary(lm(X1 ~ Y, data = iris)) # Résumé
summary(lm(X1 ~ Y, data = iris))$r.squared # R2
```

Extension à chacune des variables
```{r Ajustement du modèle linéaire de chaque X en fonction de Y}
sapply(names(iris)[-5], 
       function(x) summary(lm(as.formula(paste(x,"~ Y")), 
                              data = iris))$r.squared)
```

6. Commenter ces résultats : Ici la variable que dont la variance est la mieux expliquée par $Y$ est la variable $X_4$

$$
R^2_{X_4 / Y} = \frac{\mbox{Variance de }X_4 \mbox{ expliquée par } Y }{\mbox{Variance de }X_4} = 92,8\%
$$

Calcul de l'ANOVA (calcul de la p-value du test)
```{r}
anova(lm(X1~Y,data=iris)) 
anova(lm(X1~Y,data=iris))$`Pr(>F)`
anova(lm(X1~Y,data=iris))$`Pr(>F)`[1]
```

Extension à chacune des variables
```{r}
sapply(names(iris)[-5], 
       function(x) anova(lm(as.formula(paste(x,"~ Y")), 
                            data = iris))$`Pr(>F)`[1])
```

7. Commentez ces résultats : la sous-espèce a-t'elle un effet significatif sur l'espérance de X1 ? de X2 ? de X3 ? de X4 ? Sur l'espérance de $X = \begin{pmatrix} X_1 \\ X_2 \\ X_3 \\ X_4 \end{pmatrix}$  ? 

Oui la sous-espéce à un effet significatif sur chacune des variables explicatives.


Ici vous avez testé :
$$
H_{0j} = \{ \mu_{1j} = \mu_{2j} = \mu_{3j} \} \mbox{ contre } H_{1j} = \{\exists i \neq i'|  \mu_{ij} \neq \mu_{i'j} \},
$$
pour $j \in \{1,2,3,4\}$, c'est-à-dire pour chacune des variables séparément.

Mais, ce que nous souhaitons tester ici est : y-a-t'il une différence entre groupes pour au moins une des variables ? : 
$$
H_{0} = \{ \mu_{1} = \mu_{2} = \mu_{3} \} \mbox{ contre } H_{1} = \{\exists j \in \{1,2,3,4\}, \exists i \neq i'|  \mu_{ij} \neq \mu_{i'j} \}
$$
avec $\mu_i = \begin{pmatrix} \mu_{i1} \\ \mu_{i2} \\ \mu_{i3} \\ \mu_{i4}\end{pmatrix}$.

Comment recoller les morceaux ??? 

Remarquons d'abord que : 
$$
H_0 = \cap_{j=1}^{4} H_{0j} = H_{01} \cap H_{02} \cap H_{03} \cap H_{04}
$$ 

Ainsi $H_0$ est fausse du moment qu'au moins une des $H_{0j}$ est fausse. La question est alors quel est le risque de première espèce $\alpha_{global}$ de rejeter $H_0$ à tord quand on se donne un risque de première espèce $\alpha$ de rejeter $H_{0j}$ à tord pour $j \in \{1,2,3,4\}$ ? Et comment choisir $\alpha$ de manière à maintenir un risque global $\alpha_{global}$ ?

On note $p_j$ les probabilités critiques associées à chacune de $H_{0j}$. Sous $H_{0j}$ on sait que $p_j$ suit une loi uniforme sur $[0;1]$ ($p_j \sim U([0;1])$). En notant $A_j$ l'événement $H_{0j}$ est rejeté, $A_j = \{p_j \leq \alpha \}$.

$$
P_{H_0}(\mbox{rejet de } H_0 \mbox{ à tord}) =  P_{H_0}(\cup_{j=1}^{d} A_j) = P_{H_0}(\cup_{j=1}^{d}\{p_j \leq \alpha\}) 
\leq \sum_{j = 1}^{d}P_{H_{0j}}\left(p_j \leq \alpha\right) = d \times \alpha
$$

Ainsi, si on veut s'assurer que $P_{H_0}(\mbox{rejet de } H_0 \mbox{ à tord}) \leq \alpha_{global}$, on peut choisir $\alpha = \frac{\alpha_{global}}{d}$. Il s'agit de la correction de **Bonferroni** (cette correction est plutôt frustre et on peu parfois lui préférer d'autres corrections comme l'utilisation du False Discovery Rate (FDR) qui vise à controler le pourcentage de faux positifs).

8. On se donne un risque de première espèce $\alpha_{global} = 0,05$, réaliser l'ajustement de Bonferroni. Rejettez-vous $H_0$ ?  
```{r}
alpha_glo = 0.05
d = 4
alpha = alpha_glo/d
alpha

pvalue = sapply(names(iris)[-5], 
       function(x) anova(lm(as.formula(paste(x,"~ Y")), 
                            data = iris))$`Pr(>F)`[1])
pvalue
any(pvalue < alpha) # TRUE : moins une des 
# p-valeurs est inférieure à 0,0125 donc on rejette H_0 au risque global alpha = 0,05 ! La distribution de X varie en fonction du groupe Y.
```



## MANOVA

Contrairement à la situation précédente on souhaite tester directement $H_0$ contre $H_1$, ce qui impose un modèle sur la distribution du vecteur $X$ sachant la classe $Y$ : 

- $X | Y = k \sim \mathcal{N}_d(\mu_i;\Sigma_i)$ : Hypothèse de normalité sachant la classe
- $\Sigma_1 = \Sigma_2 = \cdots = \Sigma_K = \Sigma$ : Hypothèse d'homogénéité des variances

En utilisant la fonction `ggpairs` du package `GGally` on représente les corrélations deux à deux entre les différentes variables en fonction de la variable `Y` comme suit : 

```{r Nuages de point deux a deux, message=FALSE}
library(GGally)
ggpairs(iris, columns = 1:4, aes(color = Y, alpha = 0.8))
```

9. Commenter le graphique obtenus, que dire des hypothèses de normalité et d'homogénéité des variances ? 

Ici à l'allure du nuage de point on peut éventuellement admettre un normalité classe par classe, cependant l'hypothèse d'homogénéité des variance ne semble pas vérifiée (allure du nuage de point différente d'une classe à l'autre).



A l'aide de la fonction `mshapiro.test` de la librairie `mvnormtest` réaliser un test de normalité pour chacune des classes :
```{r Test de normalité}
# install.packages("mvnormtest")
library(mvnormtest)
mshapiro.test(as.matrix(t(iris[iris$Y=="versicolor",1:4])))
mshapiro.test(as.matrix(t(iris[iris$Y=="setosa",1:4])))
mshapiro.test(as.matrix(t(iris[iris$Y=="virginica",1:4])))
```

10. Commenter : Ici on rejetterai l'hypothèse de normalité, sauf pour la classe setosa


A l'aide de la fonction contenue dans le fichier \texttt{BoxMTest.R} on réalise le test d'égalité des matrices de variances-covariances.
```{r Test M de Box}
source("BoxMTest.R") # Fichier à récupérer sur moodle
BoxMTest(iris[,1:4],iris$Y)
```

11. Commenter : Ici on rejette l'hypothèse d'homogénéité des variances. Par conséquent nous ne somme pas sous les conditions d'application du test de la MANOVA, on peut alors lui des versions non paramètriques ne reposant pas sur l'hypothèse de normalité, comme par exemple de le test de Kruskal-Wallis multivarié.


A l'aide de la fonction `manova` de R tester l'égalité des espérances des groupes : `manova(cbind(X1,X2,X3,X4) ~ Y, data = iris)`

```{r Test de la manova}
iris_manova = manova(cbind(X1,X2,X3,X4)~Y,data=iris)
```

Obtenir les résumés à partir de la fonction `summary` appliquée à l'objet précédent : 
```{r Résumé du test de la MANOVA}
summary(iris_manova) # compléter
```

12. Commenter : Ici la statistique de test utilisée est la statistique de Pillai, une transformation appliquée à la statistique de test suit approximativement une loi de Fisher à $8$ et $290$ dgegrés de liberté. Ici on rejette $H_0$.


13. Aller voir dans l'aide de la fonction `summary.manova`  pour modifier la statistique de test utilisée
```{r Statistiques de test de la MANOVA}
help("summary.manova")
summary(iris_manova,"Pillai")
summary(iris_manova,"Wilks")  
summary(iris_manova,"Hotelling-Lawley") 
summary(iris_manova,"Roy") 
```

14. Commenter les résultats obtenus : Dans chacun des cas on rejette $H_0$.


Par la suite on va calculer les matrices $W$ et $B$ qui pourraient être utilisées pour récalculer les statistiques de test ci-dessus. 


# Analyse factorielle discriminante (iris de Fisher)

## Calcul des matrices

15. Calculer $V$ la matrice de variance-covariance globale, à partir de la fonction \texttt{cov.wt} en utilisant l'option \texttt{method = "ML"}. Expliquer à quoi sert cette option.

```{r}
V = cov.wt(iris[,1:4],method = "ML")$cov
```

Attention on prendra garde de récupérer le bon élément de sortie de la fonction `cov.wt`, fonction qui ressort une liste contenant entre autres `cov`, `center`, ... 

On calcule les vecteurs des moyennes pour chaque groupe $\bar{X}_{i}$ en s'aidant de la fonction `by`, et en restructurant le résultat sous forme d'un tableau. 

Constituez la matrice $G$ de centres des classes composée d'une colonne par variable et d'une ligne par sous-espèce (on rappelle que la fonction `t` permet de transposer un tableau)
```{r}
by(iris[,1:4],iris$Y, colMeans)
simplify2array(by(iris[,1:4],iris$Y, colMeans))
G = t(simplify2array(by(iris[,1:4],iris$Y, colMeans)))
```


16. En déduire : 
$$
B = \sum_{i=1}^{K}\frac{n_i}{n}(\bar{X}_{i}-\bar{X})(\bar{X}_{i}-\bar{X})^T
$$
où $\bar{X}_{i}$, $\bar{X}$ sont respectivement les vecteurs colonnes des moyennes intra-classes et de la moyenne globale. Pour cela on pourra remarquer que $B$ est la matrice de covariance des centres des classes pondérés par leurs effectifs (penser à `cov.wt` et à son argument `wt`). 
```{r}
B = cov.wt(G, wt = as.vector(table(iris$Y)) , method = "ML")$cov
```

Calcul de W : 
```{r}
Wi = lapply(levels(iris$Y), function(k)
  cov.wt(iris[iris$Y== k,1:4],method="ML")$cov) # Liste de Wi
ni = table(iris$Y)  # Vecteur de ni

W = Reduce('+',Map('*',Wi,ni))/sum(ni)
```



17. Vérifier qu'on retrouve bien : $V = W + B$
```{r}
# Proposer un indicateur synthétique du fait que V = W + B
norm(V - (W + B)) 
```



## Réalisation de l'AFD

On rappelle que dans R l'ACP peut se réaliser à la main comme suit :
```{r}
eigen(V) # Decomposition en valeurs propres
eigen(V)$values
ACP=eigen(V)$vectors
c=as.matrix(iris[,1:4])%*%ACP[,1:2]
plot(c,col=iris$Y)

c = as.data.frame(c)
names(c) <- c("C1","C2")
c %>% mutate(Y = iris$Y) %>% 
  ggplot(aes(x = C1, y = C2, color = Y, shape = Y)) + 
  geom_point()
```

18. Commenter, quel est le pourcentage d'inertie expliqué par chacun des axes ? Pour les deux premiers axes

```{r}
l = eigen(V)$values
l
prop_var = l/sum(l) # 0.924618723 0.053066483 0.017102610 0.005212184
cumsum(prop_var)
```


19. Calculer les coordonnées $d_1$ et $d_2$ des points projetés sur les deux premières composantes discriminantes, sachant qu'en AFD on diagonalise la matrice $V^{-1}B$. Adapter le code pour réaliser l'AFD, et commenter les résultats (on rappelle que l'inverse s'obtient avec la fonction `solve` et le produit matriciel avec l'opérateur `%*%`) : 
```{r}
M = solve(V) %*% B
eigen(M) # Decomposition en valeurs propres
eigen(M)$values
AFD=eigen(M)$vectors
d=as.matrix(iris[,1:4])%*%AFD[,1:2]
plot(d,col=iris$Y)

d = as.data.frame(d)
names(d) <- c("D1","D2")
d %>% mutate(Y = iris$Y) %>% 
  ggplot(aes(x = D1, y = D2, color = Y, shape = Y)) + 
  geom_point()

```

Quels est la part de variance de $d_1$ expliquée par la classe ? De $d_2$

20. Reprendre le code précédent en remplaçant $V^{-1}B$ par $W^{-1}B$. 
```{r}
eigen(solve(V) %*% B)$vectors 
eigen(solve(W) %*% B)$vectors

l = eigen(solve(V) %*% B)$values # lambda
eigen(solve(W) %*% B)$values # lambda/(1-lambda)
l/(1-l)
```
Que dire ? Quel est le lien entre les différents vecteurs propres et valeurs propres ?


21. Comparer les résultats obtenus à ceux obtenus en ACP.


## Calcul des scores discriminants

On souhaite calculer les fonctions de score pour chacun des groupes, ces fonctions nous serviront ensuite à affecter chaque individu au groupe de plus grand score (équivalent à la minimisation de la distance de Mahalanobis).

On rappelle que le calcul des fonctions de score pour chaque groupe s'effectue comme suit : 
$$
s_i(x) = \alpha_{i0} + \alpha_{i1}x_1 + \alpha_{i2}x_2 + \alpha_{i3}x_3 + \alpha_{i4}x_4 
$$
avec $\alpha_{i0} = - \bar{X}_i^T W^{-1} \bar{X}_i$ et 
$$
\begin{pmatrix} \alpha_{i1} \\ \vdots \\ \alpha_{ip} \end{pmatrix} = 2 W^{-1} \bar{X}_i
$$

22. Construire le tableau des coefficients :

|          |Setosa         | Versicolor    | Virginica    |
|----------|---------------|---------------|--------------| 
|Constante | $\alpha_{10}$ | $\alpha_{20}$ | $\alpha_{30}$|
|$X_1$     | $\alpha_{11}$ | $\alpha_{21}$ | $\alpha_{31}$|
|$X_2$     | $\alpha_{12}$ | $\alpha_{22}$ | $\alpha_{32}$|
|$X_3$     | $\alpha_{13}$ | $\alpha_{23}$ | $\alpha_{33}$|
|$X_4$     | $\alpha_{14}$ | $\alpha_{24}$ | $\alpha_{34}$|


Exemple à la main : 
```{r}
i = 1 # Classe 1 (setosa)
dim(G[i,])
dim(G[i,,drop = FALSE])
Xi <- matrix(G[i,],4,1)
# Xi <- t(G[i,,drop = FALSE])
- t(Xi) %*% solve(W) %*% Xi  # Premier alpha_{i0}
2 * solve(W) %*% Xi # Les 4 autres ! 
```

Mise en production !
```{r}
alpha=matrix(0,5,3)
rownames(alpha) = c("intercept","X1","X2","X3","X4")
colnames(alpha) = levels(iris$Y)
for (i in 1:3) {
  barXi=matrix(G[i,],4,1) # centres de Xj pour Y=i
  alpha[1,i]=-t(barXi)%*%solve(W)%*%barXi
  alpha[2:5,i]=2*solve(W)%*%barXi
}
alpha
```


Aide : Dans l'AFD, la notion de score est liée au calcul de la règle de décision. Une observation $x = (x_1, x_2, x_3, x_p)$ sera affectée au groupe avec le score $s_i(x)$ maximal.

Rappel :
$$
\hat{y} = \arg\min_i (x - \bar{X}_i)^T W^{-1} (x - \bar{X}_i) 
$$
Ce calcul revient à maximiser $2 x^T W^{-1} \bar{X}_i - \bar{X}_i^T W^{-1}\bar{X}_i$. 

23. Calculer les scores des individus à partir de cette règle (simple calcul matriciel, on pourra rajouter une colonne de 1 à la matrice des données à l'aide de la fonction `cbind`)

Exemple à la main pour le calcul des scores
```{r}
alpha[1,1] + sum(iris[1,1:4] * alpha[2:5,1]) # Score pour l'individu 1 dans la classe 1
c(1,as.matrix(iris[1,1:4])) %*% alpha[,1, drop = FALSE]
c(1,as.matrix(iris[1,1:4])) %*% alpha
head(as.matrix(cbind(1,iris[1:4])) %*% alpha)
```


Score individu : simple produit matriciel
```{r}
s=as.matrix(cbind(1,iris[,1:4]))%*%alpha
s[1:10,]
names(which.max(s[150,]))
Ypredit = apply(s, 1, function(x) names(which.max(x)))
```


24. En déduire le classement de chacun des individus à partir de ces scores (en utilisant de façon appropriée les fonctions `apply` et `which.max`) : 

On affecte l'individu dans la colonne où le score est le plus élevé :
```{r}
Ypredit=levels(iris$Y)[apply(s,1,which.max)]
Ypredit[1:10]
table(Ypredit)
table(Y = iris$Y,Ypredit) # Matrice de confusion
TBC = mean(iris$Y == Ypredit)
TBC
TMC = mean(iris$Y != Ypredit)
TMC
```
























## Introduction

**Références :** 

- Site du livre R for data Science de Hardley Wickam (le must mais en anglais) :
https://r4ds.had.co.nz
- Doc très complète en Français sur R au goût du jour :
https://larmarange.github.io/analyse-R/analyse-R.pdf, site web associé 
https://larmarange.github.io/analyse-R
- Statistiques avec R, PA. Cornillon, A. Guyader, F. Husson, N. Jégou, J. Josse, M. Kloareg, E. Matzner-Léber, L. Rouviére, Presses Universitaire de Rennes, livre plus anciens mais décrit bien les principaux objets manipulés en R

**Organisation :** 10 séances de TP de 1h30 = 15h au total

**Evaluation :**

- 2 interrogations séances 3 et 9
- 1 Devoir Surveillé séance 10

MoyenneCC = 0.5 x IE1 + 0.5 x IE2

Moyenne = (MoyenneCC + DevoirSurveillé) / 2

**Avantage et inconvenients**

Langage R : langage de programmation statistique. 

*Avantages :*

- libre
- bien adapté à la manipulation de données
- de nombreux modules disponibles
- de plus en plus utilisé (même en entreprise)
- interfaçable avec de nombreux autres langages
- possibilité de réaliser des graphiques de grande qualité : ggplot2, plotly
- possibilité de générer des documents : RMarkdown
- possibilité de générer des interface web : Shiny
- innovation sur méthodes statistiques passe plus par R que par SAS aujourd'hui

*Inconvénients :*

- langage moins "carré" que certains autres du point de vue des puristes de la programmation : typage dynamique, ...
- programme plus long à s'exécuter que dans certains autres langages : Python, Java, C++, 


**Notions abordées**

1. Concepts
2. Manipuler les données
3. Représenter les données
4. Programmer en R


## Objets R

### Création d'objets 

La création d'un objet peut se faire par affection avec un des trois opérateurs "<-", "->" ou "="

```{r cmd5}
b <- 41.3 # crée l'objet b en lui donnant la valeur 41.3
x <- b    # x reçoit la valeur b  
x = b     # x reçoit la valeur b
b -> x    # x reçoit la valeur b
```

Si l'objet n'existe pas, l'affectation le crée, sinon l'affectation écrase la valeur précédente. 

On peut afficher x via la commande :
```{r cmd6}
print(x)
```

ou simplement par :
```{r cmd7}
x
```

Par défaut, R conserve en mémoire tous les objets créés. Pour connaître la liste des objets créés dans la session, on utilise :
```{r cmd8}
ls()
objects()
```

Pour supprimer l'objet x on utilise :

```{r cmd9}
rm(x)
```

Créer un objet nommé `y` et contenant la valeur 3, puis afficher `y`
```{r mon-objet, exercise = TRUE}

```

Dans le code suivant on crée l'objet `z` comme suit : 
```{r print_z}
z = 9
```






### Types d'objets

Différents types d'objets (modes) existent :

* **null** (objet vide) : `NULL`
* **logical** (booléen) : `TRUE`, `FALSE` ou `T`, `F`
* **numeric** (nombre réel) : 1, 2.341, pi, 1e-10
* **complex** (nombre complexe) : 2+0i, 2i
* **character** (chaîne de caractères) : 'bonjour', "K"

Pour connaître le mode d'un objet il suffit d'exécuter la commande `mode(objet)` :
```{r cmd10}
x = 3
mode(x)
x = T 
mode(x)
x = "K"
mode(x)
```

On peut tester l'appartenance d'un objet à un mode : 

```{r cmd11}
is.null(x)
is.logical(x)
is.numeric(x)
is.complex(x)
is.character(x)
```

Il est possible de convertir un objet x d'un mode à un autre de façon explicite :
```{r cmd12}
as.logical(x)
as.numeric(x)
as.complex(x)
as.character(x)
```

Attention les conversions retournent toujours un résultat même s'il n'a pas sens :

|De       | en        | Fonction     |   Conversions             |
|---------|-----------|--------------|---------------------------|
|logique  | numérique |  as.numeric  |  FALSE -> 0, TRUE -> 1 |
|logique  | caractére |  as.character| FALSE -> "FALSE", TRUE -> "TRUE" |
|caractère| numérique |  as.numeric  | "1","2", ... -> 1, 2, ... ; "A" -> NA |
|caractère| logique   |  as.logical  | "FALSE", "F" -> FALSE ; "TRUE", "T" -> TRUE ; autres caractéres -> NA|
|numérique| logique   |  as.logical  | 0 -> FALSE ; autres nombres -> TRUE |
|numérique| caractére | as.character | 1, 2, ... -> "1", "2", ... |

Un objet a deux attributs intrinsèques : son mode `mode()` et sa longueur `length()`.

Il existe enfin des attributs spécifiques selon le type d'objet : `dim`, `dimnames`, `class`, `names`. La liste de ces attributs peut être obtenue à l'aide de la commande `attributes(objet)`.

```{r q1, echo=FALSE}
question("La fonction qui permet de  convertir une variable en numérique est :",
  answer("is.numeric", message = "is.numeric retourne un booléen indiquant si la variable est numérique ou non"),
  answer("as.numeric", correct = TRUE),
  allow_retry = TRUE
)
```

```{r q2, echo=FALSE}
question("Que retourne la commande as.numeric('B')",
  answer("2"),
  answer("NA", correct = TRUE),
    allow_retry = TRUE
)
```

Compléter le code suivant pour obtenir le mode de `x` 
```{r conversion, exercise = TRUE}
x = "A"
```

```{r conversion-hint}
"Penser à utiliser la fonction `mode`"
```


```{r conversion-solution}
mode(x)
```

```{r conversion-check}
grade_code()
```


### Valeurs manquantes

Les valeurs manquantes sont codées par `NA`, qui a des régles de calcul spécifiques : 

```{r cmd13}
x <- NA
x + 1
```

Pour savoir où se trouvent les valeurs manquantes d'un objet, on peut utiliser : 

```{r cmd14}
is.na(x)
```

On peut aussi avoir d'autres types de valeurs telles que Inf ou NaN (Not A Number) :

```{r cmd15}
exp(1e10)
log(-2)
```

Expliquer le résultat suivant, et corriger le code pour obtenir un résultat cohérent avec ce que disent les mathématiques : 
```{r precision, exercise = TRUE}
exp(1000)/(1 + exp(1000))
```

```{r precision-hint}
exp(x)/(1 + exp(x)) = 1/(1 + exp(-x))
```


### Les vecteurs

Différentes méthodes sont possibles pour construire un vecteur : 

Fonction collecteur c :

```{r cmd16}
x <- c(5.6,3.45,-3.1,4.3) # vecteur numérique de 4 éléments
x
x <- c(x,3,c(12,8)) # vecteur à 7 éléments
x
x <- 2 # vecteur de longueur 1
x
```


Opérateur séquence ":"

```{r cmd17}
1:12
```

Fonction seq : 

```{r cmd18} 
seq(1,6, by = 0.5)
seq(1,6,length = 5)
```

Fonction rep :
```{r}
rep(1,4)
rep(c(1,2),each = 3)
```


Créer le vecteur constitué des nombre pair de 8 à 24
```{r exo-suite, exercise = TRUE}

```

Créer le vecteur qui répéte une fois le chiffre 1, 2 fois le chiffre 2, ..., 10 fois le chiffre 10. Indice : l'argument each  dans la fonction rep peut être lui aussi un vecteur :
```{r exo-rep, exercise = TRUE}

```


Vecteurs de caractères :

```{r cmd20}
x <- c("A","BB","C1")
x
x <- rep('A',5)
```

Lancer le code suivant, et adapter pour que l'alphabet soit répété quatre fois.
```{r}
letters
```

Le nombre d'élèment d'un vecteur peut être déterminé à l'aide de la fonction length : 
```{r}
length(letters)
```


Concaténation à l'aide de la fonction paste :
```{r cmd21}
paste("X",1:5,sep="-")
paste(c("X","Y"),1:5,"txt",sep=".")
paste(c("X","Y"),1:5,sep=".",collapse = "+")
```

`collapse` rassemble tous les éléments en un vecteur de longueur 1.

Créer la chaine de caratères "a + b + c + ... + z" :
```{r alphabet, exercise = TRUE}

```

Créer le vecteur des chaînes de caractère  "a1.txt", "a2.txt", "b1.txt", "b2.txt", ... "z1.txt", "z2.txt" : 
```{r alphabet2, exercice = TRUE}

```
Indice : s'aider de rep, et du fait que R recycle le vecteur plus court


Pour l'extraction de sous-chaînes de caractères on utilise la fonction `substr` :

```{r cmd22}
substr("freerider",5,9)
```

La fonction nchar permet d'obtenir le nombre de carctères d'une chaîne de caractères : 
```{r}
nchar("freerider")
```

Dans le code suivant êtraire les trois dernières lettre de la variable `mot` sans compter à la main le nombre de caractères ...
```{r extract, exercise = TRUE}
mot = "statistique"

```


On peut générer des vecteurs logiques à l'aide des opérateurs logiques : ">", ">=", "<", "<=", "==", "!=", ...

```{r cmd23}
1 > 0 
x = c(-2,5,-1,4,5)
x > 0
```

La commande retourne un vecteur logique **de la même dimension** que x.

Lors d'opérations arithmétiques `TRUE` est converti en 1 et FALSE en 0.

```{r cmd24}
x <- c(-1,0,2)
x>1
(1+x^2)*(x>1)
```

On peut utiliser les fonctions `all` ou `any`. `all` renvoie `TRUE` si tous les éléments satisfont la condition et `FALSE` sinon. `any` renvoie `TRUE` si au moins un élément satisfait la condition et `FALSE` sinon. 

```{r cmd25}
all(x>1)
any(x>1)
```

La sélection d'une partie d'un vecteur s'opére à l'aide de l'opérateur `[ ]` :

```{r cmd26}
vecteurdeselection <- c(1,3)
x[vecteurdeselection]   
```

Le vecteur de sélection peut être : 

* un vecteur d'entiers positifs
* un vecteur d'entiers négatifs
* un vecteur logique

La solution à partir d'un vecteur d'entiers positifs est la plus naturelle, les indices des éléments à sélectionner doivent être compris entre `1` et `length(x)`, la longueur du vecteur d'indices peut être quelconque.

```{r cmd27}
v <- 1:100 # entiers de 1 à 100
v[6] # le sixiéme élement de v (l'indexation commence à 1)
v[6:8] # les éléments de 6 à 8 de v
v[c(6,6,1:2)] # 6éme, 6éme, 1er, 2éme
v[10:1] # Du 10éme au 1er
```

La solution à partir d'entiers négatifs permet d'indiquer les élements à exclure :

```{r cmd28}
v[-(1:5)] # v sans les 5 premiers
v[-c(1,5)] # v sans le premier et le cinquiéme
```

Sélection à partir d'un vecteur logique de même longueur que v :

```{r cmd29}
v <- 1:15
print(v)
v[v<5]
v[(v<5)&(v>=12)] # & signifie "et"
v[(v<5)|(v>=12)] # | signifie "ou"
```

On peut sélectionner les valeurs d'un vecteur à partir des valeurs d'un autre vecteur de même longueur : 

```{r cmd30}
Temp <- c(23, 28, 24, 32)
O3 <- c(80, 102, 87, 124)
O3[Temp>25]
```

Quelques cas pratiques :
```{r cmd31}
x <- c(45,NA,23,NA,NA,67)
x
x[is.na(x)] <- 0 # NA remplacés par 0
x
y <- c(-6,3,4,-2,-1,-7)
y[y<0] <- -y[y<0] # valeurs négatives remplacées par leur opposé
y
```

Equivalent ?
```{r cmd32}
y <- c(-6,3,4,-2,-1,-7)
abs(y)
```

La recherche du min ou du max peut se faire comme suit :
```{r cmd33}
x = c(4,6,-1,7)
which.min(x)
which(x==min(x))
(1:length(x))[x == min(x)]
```


## Exercice 1

1. Créer un vecteur v comportant les entiers pairs de 2 à 40

```{r exo1q1, exercise=TRUE}

```

2. Donner la longueur du vecteur v en utilisant la commande adéquate

```{r exo1q2, exercise=TRUE}

```

3. L'opérateur %% donne le reste de la division entiére, commenter la commande v%%3

```{r exo1q3, exercise=TRUE}

```

4. Afficher uniquement les éléments du vecteur v qui sont divisibles par 3

```{r exo1q4, exercise=TRUE}

```

5. Afficher les éléments 1 à 4 du vecteur v

```{r exo1q5, exercise=TRUE}

```

6. Répéter 3 fois le vecteur v

```{r exo1q6, exercise=TRUE}

```

7. Afficher les éléments de v strictement supérieurs à 13 et inférieurs ou égaux à 28

```{r exo1q7, exercise=TRUE}

```

8. Afficher tous les éléments sauf les éléments 4 à 8 et l'élément 10 du vecteur v

```{r exo1q8, exercise=TRUE}

```

9. Afficher le premier et le dernier élément de v

```{r exo1q9, exercise=TRUE}

```




